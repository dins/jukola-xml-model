{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import matplotlib.pyplot as plt\n",
    "import shared\n",
    "\n",
    "ve_or_ju = \"ve\"\n",
    "year = 2019\n",
    "import time\n",
    "\n",
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import static_individual_estimates\n",
    "static_individual_estimates.estimate_paces(ve_or_ju)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "static_individual_estimates.combine_estimates_with_running_order(ve_or_ju)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_order = pd.read_csv(f\"data/running_order_2019_with_estimates_{ve_or_ju}.tsv\", delimiter=\"\\t\")\n",
    "display(running_order.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = running_order[[\"team_id\", \"team\", \"leg\", \"leg_dist\", \"orig_name\", \"final_pace_mean\", \"final_pace_std\", \"num_runs\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = order.rename(index=str, columns={\"orig_name\": \"name\", \"leg_dist\": \"dist\", \"final_pace_mean\": \"log_mean\", \"final_pace_std\": \"log_std\"})\n",
    "\n",
    "order.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_teams = order.set_index([\"team_id\", \"leg\"]).unstack()\n",
    "by_teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(by_teams.shape)\n",
    "# remove teams that have not nominated runners for all legs\n",
    "by_teams = by_teams[np.all(np.isfinite(by_teams[\"log_mean\"]), axis=1)]\n",
    "display(by_teams.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_legs = shared.num_legs[ve_or_ju]\n",
    "changeover_closing_timedelta = shared.changeover_closing[ve_or_ju][year] - shared.start_timestamp[ve_or_ju][year]\n",
    "changeover_closing_mins = changeover_closing_timedelta.total_seconds() / 60\n",
    "display(changeover_closing_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ve_or_ju == \"ju\":\n",
    "    dark_period_start_timedelta = shared.dark_period[year][\"start\"] - shared.start_timestamp[ve_or_ju][year]\n",
    "    dark_period_start_mins = dark_period_start_timedelta.total_seconds() / 60\n",
    "    dark_period_end_timedelta = shared.dark_period[year][\"end\"] - shared.start_timestamp[ve_or_ju][year]\n",
    "    dark_period_end_mins = dark_period_end_timedelta.total_seconds() / 60\n",
    "else:\n",
    "    # hack to disbale calculation for Venlas\n",
    "    dark_period_start_mins = 10000\n",
    "    dark_period_end_mins = -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sum of log normal variables is not defined \n",
    "# so we simulate 10000 runs for each user and sum them and then do statistics on simulated results \n",
    "def simulate_relay_estimates(row):\n",
    "    samples = pd.DataFrame()\n",
    "    for i in range(1, num_legs + 1):\n",
    "        if np.isnan(row[\"log_mean\"][i]):\n",
    "            print(row[\"log_mean\"])\n",
    "            print(row[\"name\"])\n",
    "        samples[i] = row[\"dist\"][i] * lognorm.rvs(s = row[\"log_std\"][i], scale = np.exp(row[\"log_mean\"][i]), size = 10000)\n",
    "\n",
    "    personal_start95 = samples.quantile(0.025)\n",
    "    personal_end95 = samples.quantile(0.975)\n",
    "    personal_median = samples.median()\n",
    "        \n",
    "    samples_sums = pd.DataFrame()\n",
    "    # leg_1 \n",
    "    # leg_1 + leg_2\n",
    "    # leg_1 + leg_2 + leg_3\n",
    "    # ...\n",
    "    for i in range(1,num_legs + 1):\n",
    "        samples_sums[i] = np.sum([ samples[j] for j in range(1,i+1) ], axis=0)\n",
    "\n",
    "    start95 = samples_sums.quantile(0.025)\n",
    "    end95 = samples_sums.quantile(0.975)\n",
    "    medians = samples_sums.median()\n",
    "    means = samples_sums.mean()\n",
    "    \n",
    "    before_changeover_closing_samples = samples_sums < changeover_closing_mins\n",
    "    \n",
    "    mass_start = 1 - before_changeover_closing_samples.mean()\n",
    "    # mass start of runner depends on arrival of previous runner\n",
    "    mass_start = mass_start.shift(1, fill_value=0)\n",
    "\n",
    "    not_dark_during_leg_samples = pd.DataFrame()\n",
    "    for i in range(1,num_legs + 1):\n",
    "        if i == 1:\n",
    "            start = 0\n",
    "        else:    \n",
    "            start = samples_sums[i - 1]\n",
    "            \n",
    "        finish = samples_sums[i]\n",
    "        finish_before_sunset = finish < dark_period_start_mins\n",
    "        start_after_sunrise = start > dark_period_end_mins\n",
    "        not_dark_during_leg_samples[i] = finish_before_sunset | start_after_sunrise \n",
    "    \n",
    "    dark_during_leg = 1 - not_dark_during_leg_samples.mean()    \n",
    "    \n",
    "    sum_logs = np.log(samples_sums)\n",
    "    sum_log_means = np.mean(sum_logs)\n",
    "    sum_log_stds = np.std(sum_logs)\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(1, num_legs + 1):\n",
    "        bins = int(samples_sums[i].max() - samples_sums[i].min())\n",
    "        name = row[\"name\"][i]\n",
    "        plt.title(f\"{name} bins = {bins}\")\n",
    "        plt.hist(samples_sums[i], bins=bins)\n",
    "        #plt.axvline(x=row[\"fin_real\"][i], color=\"r\")        \n",
    "        plt.axvline(x=medians[i], color=\"g\")\n",
    "        plt.axvline(x=means[i], color=\"yellow\")\n",
    "        plt.show()    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    bins = int( (samples_sums.max().max() - samples_sums.min().min()) / 5) \n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.title(f\"Whole team, bins = {bins}\")\n",
    "    plt.hist([samples_sums[1], samples_sums[2], samples_sums[3], samples_sums[4], samples_sums[5], samples_sums[6], samples_sums[7]], bins=bins)\n",
    "    for i in range(1, num_legs + 1):\n",
    "        #plt.axvline(x=row[\"fin_real\"][i], color=\"r\")\n",
    "        plt.axvline(x=medians[i], color=\"g\")\n",
    "\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    fin_start95_dict = {f\"fin_start95_{leg}\" : start95.values[leg-1] for leg in range(1, num_legs + 1)}\n",
    "    fin_end95_dict = {f\"fin_end95_{leg}\" : end95.values[leg-1] for leg in range(1, num_legs + 1)}\n",
    "    fin_median_dict = {f\"fin_median_{leg}\" : medians.values[leg-1] for leg in range(1, num_legs + 1)}\n",
    "    fin_mean_dict = {f\"fin_mean_{leg}\" : means.values[leg-1] for leg in range(1, num_legs + 1)}\n",
    "    fin_sum_log_means_dict = {f\"fin_sum_log_mean_{leg}\" : sum_log_means.values[leg-1] for leg in range(1, num_legs + 1)}\n",
    "    fin_sum_log_stds_dict = {f\"fin_sum_log_std_{leg}\" : sum_log_stds.values[leg-1] for leg in range(1, num_legs + 1)}\n",
    "    mass_start_dict = {f\"mass_start_{leg}\" : mass_start.values[leg-1] for leg in range(1, num_legs + 1)}\n",
    "    dark_during_leg_dict = {f\"dark_during_leg_{leg}\" : dark_during_leg.values[leg-1] for leg in range(1, num_legs + 1)}\n",
    "\n",
    "    personal_start95_dict = {}\n",
    "    personal_end95_dict = {}\n",
    "    personal_median_dict = {}\n",
    "    for leg in range(1, num_legs + 1):\n",
    "        personal_start95_dict[f\"personal_start95_{leg}\"] = personal_start95.values[leg-1]\n",
    "        personal_end95_dict[f\"personal_end95_{leg}\"] = personal_end95.values[leg-1]\n",
    "        personal_median_dict[f\"personal_median_{leg}\"] = personal_median.values[leg-1]\n",
    "        \n",
    "    new_cols = {**fin_start95_dict, \n",
    "                **fin_end95_dict, \n",
    "                **fin_median_dict, \n",
    "                **fin_mean_dict, \n",
    "                **fin_sum_log_means_dict, \n",
    "                **fin_sum_log_stds_dict, \n",
    "                **mass_start_dict, \n",
    "                **dark_during_leg_dict,\n",
    "                **personal_start95_dict,\n",
    "                **personal_end95_dict,\n",
    "                **personal_median_dict}\n",
    "\n",
    "    #print(start95.values)\n",
    "    #print(new_cols)\n",
    "    return pd.Series(new_cols)\n",
    "\n",
    "relay_estimates = by_teams.apply(simulate_relay_estimates, axis=1)\n",
    "relay_estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the troublesome multi-index to field_{leg} etc...\n",
    "by_teams_flat = by_teams.copy()\n",
    "by_teams_flat.columns = [f'{x[0]}_{x[1]}' for x in by_teams_flat.columns]\n",
    "by_teams_flat.reset_index()\n",
    "by_teams_flat.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = pd.concat([by_teams_flat, relay_estimates], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_1_cols = list(filter(lambda c: \"_1\" in c,estimates.columns.values))\n",
    "column_base_names = list(map(lambda c: c[:-2], leg_1_cols))\n",
    "runner_estimates = pd.wide_to_long(estimates.reset_index(), stubnames=column_base_names, i =\"team_id\", j=\"leg\", sep = \"_\")\n",
    "runner_estimates = runner_estimates.sort_values(by=['team_id', 'leg'])\n",
    "#runner_estimates = runner_estimates.drop(['team_base_name', 'estimated_log_means', 'estimated_log_stdevs'], axis=1)\n",
    "runner_estimates.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_estimates[runner_estimates['team'].str.contains(\"Reak\")][[\"name\", \"fin_start95\", \"fin_median\", \"fin_end95\", \"mass_start\", \"dark_during_leg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert minutes to date and times\n",
    "start_timestamp = shared.start_timestamp[ve_or_ju][2019]\n",
    "local_start_ts = pd.Timestamp(start_timestamp).tz_localize(None)\n",
    "\n",
    "runner_estimates[\"fin_time_median\"] = pd.to_datetime(runner_estimates[\"fin_median\"] * 60, unit = \"s\", origin= local_start_ts)\n",
    "runner_estimates[\"fin_time_start95\"] = pd.to_datetime(runner_estimates[\"fin_start95\"] * 60, unit = \"s\", origin= local_start_ts)\n",
    "runner_estimates[\"fin_time_end95\"] = pd.to_datetime(runner_estimates[\"fin_end95\"] * 60, unit = \"s\", origin= local_start_ts)\n",
    "\n",
    "runner_estimates[\"personal_estimate_interval\"] = runner_estimates[\"personal_end95\"] - runner_estimates[\"personal_start95\"]\n",
    "runner_estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for_print = runner_estimates.copy()\n",
    "for_print = for_print.reset_index()\n",
    "for_print = for_print.set_index('team_id')\n",
    "for_print = for_print.round(2)\n",
    "for_print[\"median\"] = for_print[\"fin_time_median\"].dt.strftime(\"%H:%M\")\n",
    "for_print[\"start95\"] = for_print[\"fin_time_start95\"].dt.strftime(\"%H:%M\")\n",
    "for_print[\"end95\"] = for_print[\"fin_time_end95\"].dt.strftime(\"%H:%M\")\n",
    "\n",
    "for_print[for_print['team'].str.contains(\"Stadin\")]\n",
    "#for_print = for_print[for_print['team'].str.contains(\"Puskasilim√§t\")]\n",
    "\n",
    "for_print = for_print[[\n",
    " 'leg',\n",
    " 'name', \n",
    " 'num_runs', \n",
    " 'personal_start95', \n",
    " 'personal_median',\n",
    " 'personal_end95',\n",
    " 'personal_estimate_interval']]\n",
    "\n",
    "for_print.to_csv(f'data/for_print_{ve_or_ju}_2019.csv')\n",
    "for_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for_web = runner_estimates.copy().reset_index()\n",
    "for_web[\"fin_time_median\"] = for_web[\"fin_time_median\"].dt.tz_localize('EET').dt.tz_convert('UTC')\n",
    "for_web[\"fin_time_start95\"] = for_web[\"fin_time_start95\"].dt.tz_localize('EET').dt.tz_convert('UTC')\n",
    "for_web[\"ind_log_mean\"] = for_web[\"log_mean\"]\n",
    "for_web[\"ind_log_std\"] = for_web[\"log_std\"]\n",
    "\n",
    "for_web[\"fin_time_end95\"] = for_web[\"fin_time_end95\"].dt.tz_localize('EET').dt.tz_convert('UTC')\n",
    "\n",
    "#for_web[\"fin_time_median\"] = for_web[\"fin_time_median\"].dt.strftime(\"%H:%M\")\n",
    "#for_web[\"fin_time_start95\"] = for_web[\"fin_time_start95\"].dt.strftime(\"%H:%M\")\n",
    "#for_web[\"fin_time_end95\"] = for_web[\"fin_time_end95\"].dt.strftime(\"%H:%M\")\n",
    "for_web = for_web[[\n",
    " 'team_id',\n",
    " 'leg',\n",
    " 'team',\n",
    " 'name',\n",
    " 'num_runs',     \n",
    " 'ind_log_mean', \n",
    " 'ind_log_std',\n",
    " 'personal_start95', \n",
    " 'personal_median',\n",
    " 'personal_end95',    \n",
    " 'fin_sum_log_mean', \n",
    " 'fin_sum_log_std',\n",
    "  'fin_time_start95', \n",
    " 'fin_time_end95',\n",
    " 'fin_time_median',\n",
    " 'mass_start', \n",
    " 'dark_during_leg']]\n",
    "\n",
    "for_web[for_web['team'].str.contains(\"Jyry\")]\n",
    "#for_web[for_web['team'].str.contains(\"Downt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_web.to_json(f'web-lib/for_web_{ve_or_ju}_2019.json', orient=\"records\", date_format=\"iso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_web.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_print[['num_runs', 'personal_median', \"personal_estimate_interval\"]].groupby('num_runs').agg([\"mean\", \"count\"]).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_web[\"interval_length\"] = for_web.fin_time_end95 - for_web.fin_time_start95\n",
    "for_web[\"interval_length\"].median()\n",
    "#for_web[['leg', 'interval_length', \"num_runs\"]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_web[['leg', 'interval_length', \"num_runs\"]].groupby('leg').agg([\"mean\", \"count\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = time.time()\n",
    "shared.log_df(f\"{ve_or_ju} runtime {round(((endTime - startTime)/ 60), 2)} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
