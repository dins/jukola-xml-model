{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file_name = 'data/grouped_paces_ju.tsv'\n",
    "df_all = pd.read_csv(in_file_name, delimiter=\"\\t\")\n",
    "history = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order18 = pd.read_csv('data/running_order_j2018_ju.tsv', delimiter=\"\\t\")\n",
    "order18 = order18[np.isfinite(order18.team_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paces = df.as_matrix([\"pace_1\", \"pace_2\", \"pace_3\", \"pace_4\", \"pace_5\", \"pace_6\"])\n",
    "paces = history[[\"pace_1\", \"pace_2\", \"pace_3\", \"pace_4\", \"pace_5\", \"pace_6\"]]\n",
    "logs = np.log(paces)\n",
    "means = np.nanmean(logs, axis=1)\n",
    "stdevs = np.nanstd(logs, axis=1)\n",
    "history = history.assign(log_means=pd.Series(means).values)\n",
    "history = history.assign(log_stdevs=pd.Series(stdevs).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate values for all, but only use them if no history is available\n",
    "with_history = history[np.isfinite(history.pace_2)]\n",
    "x = with_history.mean_team_id.values\n",
    "x = x.reshape(len(x), 1)\n",
    "\n",
    "log_means = with_history.log_means.values.reshape(len(with_history.log_means), 1)\n",
    "log_means_model = linear_model.LinearRegression()\n",
    "log_means_model.fit(x, log_means)\n",
    "\n",
    "estimated_log_means = log_means_model.predict(order18.team_id.values.reshape(len(order18.team_id), 1))\n",
    "order18 = order18.assign(estimated_log_means=estimated_log_means)\n",
    "\n",
    "log_stdevs = with_history.log_stdevs.values.reshape(len(with_history.log_stdevs), 1)\n",
    "log_stdevs_model = linear_model.LinearRegression()\n",
    "log_stdevs_model.fit(x, log_stdevs)\n",
    "\n",
    "estimated_log_stdevs = log_stdevs_model.predict(order18.team_id.values.reshape(len(order18.team_id), 1))\n",
    "order18 = order18.assign(estimated_log_stdevs=estimated_log_stdevs)\n",
    "order18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine history with 2018 runners \n",
    "no_history_row = pd.DataFrame([[0,0]], columns=[\"log_means\", \"log_stdevs\"])\n",
    "def get_history_row(running_order_row):\n",
    "    name = running_order_row[\"name\"].lower()\n",
    "    \n",
    "    by_name = history[history['name'] == name]\n",
    "    by_name_and_colon = history[history['name'].str.contains(name + \":\", regex=False)]\n",
    "\n",
    "    runners = by_name.append(by_name_and_colon)\n",
    "    if(len(runners) == 1):\n",
    "        return runners\n",
    "    team_name = running_order_row[\"team_base_name\"].upper()\n",
    "    runners = runners[runners['teams'].str.contains(team_name, regex=False)]\n",
    "    if(len(runners) == 1):\n",
    "        return runners\n",
    "    if(len(runners) == 0):\n",
    "        return no_history_row\n",
    "    print(f\"name '{name}' team_name '{team_name}'\")\n",
    "    print(f\"by_name {len(by_name)} by_name_and_colon {len(by_name_and_colon)} runners {len(runners)}\")\n",
    "    print(f\"Duplicate runner {runners}\")\n",
    "    #print(f\"TEAMS by_name_and_colon {by_name_and_colon['teams']}\")\n",
    "    return runners.sort_values(\"num_runs\", ascending = False).head(1)\n",
    "\n",
    "def get_estimate_params(running_order_row):\n",
    "    history_row = get_history_row(running_order_row)\n",
    "    #print(f\"estimate_row log_means {history_row.log_means} {history_row.log_stdevs}\")\n",
    "    log_means = history_row.log_means.values[0]\n",
    "    log_stdevs = history_row.log_stdevs.values[0]\n",
    "    return pd.Series({\"history_log_means\": log_means, \"history_log_stdevs\": log_stdevs})\n",
    "\n",
    "#order18 = order18[order18['team'].str.contains(\"Reak\") | order18['team'].str.contains(\"Puskasil\") | order18['team'].str.contains(\"Rastihaukat\")]\n",
    "estimate_params = order18.apply(lambda row: get_estimate_params(row), axis=1)\n",
    "order18 = order18.assign(history_log_means = estimate_params.history_log_means)\n",
    "order18 = order18.assign(history_log_stdevs = estimate_params.history_log_stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order18['log_means'] = np.where(np.isfinite(order18[\"history_log_means\"]) & order18[\"history_log_means\"] > 0, order18[\"history_log_means\"], order18[\"estimated_log_means\"])\n",
    "order18['log_stdevs'] = np.where(np.isfinite(order18[\"history_log_stdevs\"]) & order18[\"history_log_stdevs\"] > 0, order18[\"history_log_stdevs\"], order18[\"estimated_log_stdevs\"])\n",
    "order18.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate personal estimates\n",
    "# s = sigma and scale = exp(mu).\n",
    "\n",
    "log_means = np.exp(order18['log_means']) \n",
    "log_stdevs = order18['log_stdevs']\n",
    "\n",
    "intervals95 = lognorm.interval(0.95, s = log_stdevs, scale = log_means)\n",
    "means = lognorm.mean(s = log_stdevs, scale = log_means)\n",
    "medians = lognorm.median(s = log_stdevs, scale = log_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order18 = order18.assign(ind_95_start = pd.Series(intervals95[0] * order18.leg_dist).values)\n",
    "order18 = order18.assign(ind_95_end = pd.Series(intervals95[1] * order18.leg_dist).values)\n",
    "order18 = order18.assign(ind_mean = pd.Series(means * order18.leg_dist).values)\n",
    "order18 = order18.assign(ind_median = pd.Series(medians * order18.leg_dist).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_teams = order18.set_index([\"team_id\", \"leg\"]).unstack()\n",
    "by_teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove teams missing some runners\n",
    "print(len(by_teams))\n",
    "by_teams = by_teams[np.isfinite(by_teams.log_means[1]) & np.isfinite(by_teams.log_means[2]) & np.isfinite(by_teams.log_means[3]) & np.isfinite(by_teams.log_means[4]) & np.isfinite(by_teams.log_means[5]) & np.isfinite(by_teams.log_means[6]) & np.isfinite(by_teams.log_means[7])] \n",
    "print(len(by_teams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of log normal variables is not defined \n",
    "# so we simulate 10000 runs for each user and sum them and then do statistics on simulated results \n",
    "def simulate_relay_estimates(row):\n",
    "    samples = pd.DataFrame()\n",
    "    for i in range(1,8):\n",
    "        if np.isnan(row[\"log_means\"][i]):\n",
    "            print(row[\"log_means\"])\n",
    "            print(row[\"name\"])\n",
    "        samples[i] = row[\"leg_dist\"][i] * lognorm.rvs(s = row[\"log_stdevs\"][i], scale = np.exp(row[\"log_means\"][i]), size = 10000)\n",
    "\n",
    "    samples_sums = pd.DataFrame()\n",
    "    # leg_1 \n",
    "    # leg_1 + leg_2\n",
    "    # leg_1 + leg_2 + leg_3\n",
    "    # ...\n",
    "    for i in range(1,8):\n",
    "        samples_sums[i] = np.sum([ samples[j] for j in range(1,i+1) ], axis=0)\n",
    "\n",
    "    start95 = samples_sums.quantile(0.025)\n",
    "    end95 = samples_sums.quantile(0.975)\n",
    "    medians = samples_sums.median()\n",
    "    means = samples_sums.mean()\n",
    "    \n",
    "    sum_logs = np.log(samples_sums)\n",
    "    sum_log_means = np.mean(sum_logs)\n",
    "    sum_log_stds = np.std(sum_logs)\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(1,8):\n",
    "        bins = int(samples_sums[i].max() - samples_sums[i].min())\n",
    "        name = row[\"name\"][i]\n",
    "        plt.title(f\"{name} bins = {bins}\")\n",
    "        plt.hist(samples_sums[i], bins=bins)\n",
    "        #plt.axvline(x=row[\"fin_real\"][i], color=\"r\")        \n",
    "        plt.axvline(x=medians[i], color=\"g\")\n",
    "        plt.axvline(x=means[i], color=\"yellow\")\n",
    "        plt.show()    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    bins = int( (samples_sums.max().max() - samples_sums.min().min()) / 5) \n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.title(f\"Whole team, bins = {bins}\")\n",
    "    plt.hist([samples_sums[1], samples_sums[2], samples_sums[3], samples_sums[4], samples_sums[5], samples_sums[6], samples_sums[7]], bins=bins)\n",
    "    for i in range(1,8):\n",
    "        #plt.axvline(x=row[\"fin_real\"][i], color=\"r\")\n",
    "        plt.axvline(x=medians[i], color=\"g\")\n",
    "\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    fin_start95_dict = {f\"fin_start95_{leg}\" : start95.values[leg-1] for leg in range(1,8)}\n",
    "    fin_end95_dict = {f\"fin_end95_{leg}\" : end95.values[leg-1] for leg in range(1,8)}\n",
    "    fin_median_dict = {f\"fin_median_{leg}\" : medians.values[leg-1] for leg in range(1,8)}\n",
    "    fin_mean_dict = {f\"fin_mean_{leg}\" : means.values[leg-1] for leg in range(1,8)}\n",
    "    fin_sum_log_means_dict = {f\"fin_sum_log_mean_{leg}\" : sum_log_means.values[leg-1] for leg in range(1,8)}\n",
    "    fin_sum_log_stds_dict = {f\"fin_sum_log_std_{leg}\" : sum_log_stds.values[leg-1] for leg in range(1,8)}\n",
    "    new_cols = {**fin_start95_dict, **fin_end95_dict, **fin_median_dict, **fin_mean_dict, **fin_sum_log_means_dict, **fin_sum_log_stds_dict}\n",
    "\n",
    "    #print(start95.values)\n",
    "    #print(new_cols)\n",
    "    return pd.Series(new_cols)\n",
    "\n",
    "relay_estimates = by_teams.apply(simulate_relay_estimates, axis=1)\n",
    "relay_estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(relay_estimates)\n",
    "#relay_estimates[[\"fin_sum_log_mean_1\", \"fin_sum_log_std_1\", \"fin_sum_log_mean_2\", \"fin_sum_log_std_2\", \"fin_sum_log_mean_3\", \"fin_sum_log_std_3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the troublesome multi-index to field_{leg} etc...\n",
    "by_teams_flat = by_teams.copy()\n",
    "by_teams_flat.columns = [f'{x[0]}_{x[1]}' for x in by_teams_flat.columns]\n",
    "by_teams_flat.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = pd.concat([by_teams_flat, relay_estimates], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert minutes to date and times\n",
    "start_timestamp = pd.Timestamp(year = 2018, month = 6, day = 16, hour = 23)\n",
    "\n",
    "for leg in range(1,8):\n",
    "    estimates[f\"fint_median_{leg}\"] = pd.to_datetime(estimates[f\"fin_median_{leg}\"] * 60, unit = \"s\", origin= start_timestamp)\n",
    "    estimates[f\"fint_start95_{leg}\"] = pd.to_datetime(estimates[f\"fin_start95_{leg}\"] * 60, unit = \"s\", origin= start_timestamp)\n",
    "    estimates[f\"fint_end95_{leg}\"] = pd.to_datetime(estimates[f\"fin_end95_{leg}\"] * 60, unit = \"s\", origin= start_timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort teams by estimated total time \n",
    "estimates = estimates.sort_values(\"fin_median_7\")\n",
    "\n",
    "estimates.to_csv('data/team_estimates_ju2018.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates[[\"team_1\", \"fin_median_7\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_to_follow = estimates[estimates['team_1'].str.contains(\"Reak\") | estimates['team_1'].str.contains(\"Puskasil\") | estimates['team_1'].str.contains(\"Rastihaukat\")]\n",
    "teams_to_follow[[\"team_1\", \"fin_median_7\", \"fin_start95_7\", \"fin_end95_7\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_1_cols = list(filter(lambda c: \"_1\" in c,estimates.columns.values))\n",
    "column_base_names = list(map(lambda c: c[:-2], leg_1_cols))\n",
    "runner_estimates = pd.wide_to_long(estimates.reset_index(), stubnames=column_base_names, i =\"team_id\", j=\"leg\", sep = \"_\")\n",
    "runner_estimates = runner_estimates.sort_values(by=['team_id', 'leg'])\n",
    "runner_estimates = runner_estimates.drop(['team_base_name', 'estimated_log_means', 'estimated_log_stdevs'], axis=1)\n",
    "runner_estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_estimates.to_csv('data/runner_estimates_ju2018.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_estimates[runner_estimates['team'].str.contains(\"Reak\")][[\"name\", \"log_means\", \"log_stdevs\", \"ind_median\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_print = runner_estimates.copy()\n",
    "for_print = for_print.reset_index()\n",
    "for_print = for_print.set_index('team_id')\n",
    "for_print = for_print.round(2)\n",
    "for_print.fint_median = for_print.fint_median.dt.strftime(\"%H:%M\")\n",
    "for_print.fint_start95 = for_print.fint_start95.dt.strftime(\"%H:%M\")\n",
    "for_print.fint_end95 = for_print.fint_end95.dt.strftime(\"%H:%M\")\n",
    "for_print = for_print[['team',\n",
    " 'leg',\n",
    " 'name',\n",
    " 'ind_median', \n",
    " 'ind_95_start', \n",
    " 'ind_95_end', \n",
    " 'fin_median',\n",
    " 'fint_median',\n",
    " 'fint_start95',\n",
    " 'fint_end95']]\n",
    "for_print.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_print.to_csv('for_print_ju2018_after.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_print[for_print['team'].str.contains(\"Reak\") | for_print['team'].str.contains(\"Puskasil\") | for_print['team'].str.contains(\"Rastihaukat 2\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_web = runner_estimates.copy().reset_index()\n",
    "for_web.fint_median = for_web.fint_median.dt.strftime(\"%H:%M\")\n",
    "for_web.fint_start95 = for_web.fint_start95.dt.strftime(\"%H:%M\")\n",
    "for_web.fint_end95 = for_web.fint_end95.dt.strftime(\"%H:%M\")\n",
    "for_web = for_web[[\n",
    " 'team_id',\n",
    " 'leg',\n",
    " 'team',\n",
    " 'name',\n",
    " 'fin_sum_log_mean', \n",
    " 'fin_sum_log_std',\n",
    " 'fin_median',\n",
    " 'fint_median',\n",
    " 'fint_start95',\n",
    " 'fint_end95']]\n",
    "for_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_web.to_json('web-lib/for_web_ju2018_after.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the actual times after race and analyze estimates\n",
    "results18 = pd.read_csv('data/csv-results_j2018_ju.tsv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results18 = results18[[\"team-id\", \"leg-nro\", \"leg-time\"]]\n",
    "results18[\"leg-time\"] = results18[\"leg-time\"] / 60\n",
    "results18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results18 = results18.rename(index=str, columns={\"team-id\": \"team_id\", \"leg-nro\": \"leg\"})\n",
    "runner_estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result = pd.merge(runner_estimates, results18, how='left', on=['team_id', 'leg'])\n",
    "with_result = with_result[np.isfinite(with_result[\"leg-time\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result[\"ind_error\"] = with_result.ind_median - with_result[\"leg-time\"]\n",
    "with_result[\"ind_error_perc\"] = with_result[\"ind_error\"] / with_result[\"leg-time\"]\n",
    "with_result[\"ind_in_int\"] = (with_result[\"ind_95_start\"] < with_result[\"leg-time\"]) & (with_result[\"ind_95_end\"] > with_result[\"leg-time\"])\n",
    "#viewable = with_result[['team_id', \"team\", 'leg', \"name\", \"ind_median\", \"leg-time\", \"ind_error\", \"ind_error_perc\", \"ind_in_int\"]]\n",
    "#viewable[viewable.team_id.isin([1270, 429, 1131, 1178, 1089])].sort_values(by=['ind_error_perc', 'ind_error'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "rmse(with_result.ind_median, with_result[\"leg-time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(with_result[\"leg-time\"], with_result.ind_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result[\"ind_error_perc\"].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result[\"ind_error_perc\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result[\"ind_in_int\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimate_params(result_row):\n",
    "    legs_so_far = [ i for i in range(1, result_row.leg + 1) ]\n",
    "    rows_so_far = with_result[(with_result.team_id == result_row.team_id) & (with_result.leg.isin(legs_so_far))]\n",
    "    return np.sum(rows_so_far[\"leg-time\"])\n",
    "\n",
    "#with_result = with_result[with_result.team_id.isin([1270, 429, 1131, 1178, 1089])]    \n",
    "with_result[\"real_mins\"] = with_result.apply(lambda row: get_estimate_params(row), axis=1)\n",
    "with_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(with_result.fin_median, with_result[\"real_mins\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(with_result[\"real_mins\"], with_result.fin_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result[\"team_error\"] = with_result.fin_median - with_result[\"real_mins\"]\n",
    "with_result[\"team_error_perc\"] = with_result[\"team_error\"] / with_result[\"real_mins\"]\n",
    "with_result[\"team_in_int\"] = (with_result[\"fin_start95\"] < with_result[\"real_mins\"]) & (with_result[\"fin_end95\"] > with_result[\"real_mins\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result[\"team_error_perc\"].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result[\"team_in_int\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result[['team_id', \"team\", 'leg',  'leg_dist', \"name\", \"fin_start95\", \"real_mins\", \"fin_end95\", \"team_in_int\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_result_web = with_result.copy().reset_index()\n",
    "with_result_web.fint_median = with_result_web.fint_median.dt.tz_localize('EET').dt.tz_convert('UTC')\n",
    "with_result_web.fint_start95 = with_result_web.fint_start95.dt.tz_localize('EET').dt.tz_convert('UTC')\n",
    "with_result_web.fint_end95 = with_result_web.fint_end95.dt.tz_localize('EET').dt.tz_convert('UTC')\n",
    "with_result_web = with_result_web[[\n",
    " 'team_id',\n",
    " 'leg',\n",
    " 'team',\n",
    " 'name',\n",
    " 'fin_sum_log_mean', \n",
    " 'fin_sum_log_std',\n",
    " 'fin_median',\n",
    " 'real_mins',\n",
    " 'fint_median',\n",
    " 'fint_start95',\n",
    " 'fint_end95']]\n",
    "with_result_web.to_json('web-lib/with_result_ju2018.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
