{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shared\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import prepare_run_features\n",
    "#os.environ['FORECAST_YEAR'] = \"2012\"\n",
    "#os.environ['RACE_TYPE'] = \"ju\"\n",
    "#os.environ['UNKNOWN_OR_KNOWN'] = \"unknown\"\n",
    "unknown_or_known = os.environ.get('UNKNOWN_OR_KNOWN', \"unknown\")\n",
    "runners_with_history =  unknown_or_known == \"known\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, features = prepare_run_features.prepare_run_features(runners_with_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b513e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y.shape)\n",
    "display(x.shape)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if runners_with_history:\n",
    "    runners_row_indexer = features[\"runs\"] > 1\n",
    "else:\n",
    "    runners_row_indexer = features[\"runs\"] == 1\n",
    "    \n",
    "features = features[runners_row_indexer]\n",
    "x = x[runners_row_indexer]\n",
    "y = y[runners_row_indexer]\n",
    "display(y.shape)\n",
    "display(x.shape)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08449b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05, random_state=2019)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.01, random_state=2023)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14264afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index_of_team_id = list(features.columns).index(\"team_id\")\n",
    "def fit_and_test_model(model, x_train, x_test, y_train, y_test, fit_params={}):\n",
    "    model.fit(x_train, y_train.ravel(), **fit_params)\n",
    "    y_pred = np.exp(model.predict(x_test))\n",
    "    print(f\"Shapes: y_test={np.exp(y_test).shape} y_pred={y_pred.shape}\")\n",
    "    print(\"Mean absolute percetange error: %.3f\" %  mean_absolute_percentage_error(np.exp(y_test), y_pred))\n",
    "    print(\"Median absolute error: %.3f\" %  median_absolute_error(np.exp(y_test), y_pred))\n",
    "    print(\"Mean squared error: %.3f\" % mean_squared_error(np.exp(y_test), y_pred))\n",
    "    print('Explained variance score: %.3f' % r2_score(np.exp(y_test), y_pred))\n",
    "    \n",
    "    plt.scatter(x_test[:,index_of_team_id], np.exp(y_test),  color='red', alpha=0.05)\n",
    "    plt.scatter(x_test[:,index_of_team_id], y_pred, color='blue', alpha=0.05)\n",
    "    plt.ylim(4, 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "fit_and_test_model(linear, np.nan_to_num(x_train), np.nan_to_num(x_test), y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame({'name':features.keys(), 'coef':linear.coef_})\n",
    "display(coefs.sort_values(by=\"coef\").round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a989b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge = linear_model.Ridge(alpha=0.5)\n",
    "#fit_and_test_model(ridge, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = f\"models/best_params_{unknown_or_known}_runs_hgbr_{shared.race_id_str()}.json\"    \n",
    "with open(json_path) as infile:\n",
    "    hgbr_params = json.load(infile)\n",
    "\n",
    "hgbr_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c911fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_params = {'max_depth': 6, 'n_estimators': 400, 'learning_rate': 0.08}\n",
    "#best_params = {'max_depth': 4, 'n_estimators': 799, 'learning_rate': 0.11}\n",
    "\n",
    "#best_params = {'max_depth': 7, 'n_estimators': 220, 'learning_rate': 0.15}\n",
    "#best_params = {'max_depth': 6, 'n_estimators': 331, 'learning_rate': 0.1011956627512609}\n",
    "\n",
    "#gbr = sklearn.ensemble.GradientBoostingRegressor(random_state=0, verbose=1, **best_params)\n",
    "#fit_and_test_model(gbr, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hgbr_params = {'max_depth': 6, 'max_iter': 331, 'learning_rate': 0.1011956627512609}\n",
    "\n",
    "\n",
    "hgbr = sklearn.ensemble.HistGradientBoostingRegressor(random_state=0, verbose=1, **hgbr_params)\n",
    "\n",
    "fit_and_test_model(hgbr, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04720b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful, impurity-based feature importances can be misleading for high cardinality features (many unique values). \n",
    "gbr_features = pd.DataFrame({'feature':features.columns})\n",
    "#display(gbr_features.sort_values(by=\"importance\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ff9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(hgbr, x_test, y_test, n_repeats=20,\n",
    "                                random_state=2019, n_jobs=2)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd935d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_features['perm_importances_mean'] = result.importances_mean\n",
    "gbr_features['perm_importances_std'] = result.importances_std\n",
    "#gbr_features['importance_power'] = np.sqrt(gbr_features['importance'] * gbr_features['perm_importances_mean'].abs())\n",
    "display(gbr_features.sort_values(by=\"perm_importances_mean\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hgbr_q_low = sklearn.ensemble.HistGradientBoostingRegressor(loss='quantile', quantile=0.159, random_state=0, verbose=1, **hgbr_params)\n",
    "#gbr_q_low = sklearn.ensemble.GradientBoostingRegressor(loss='quantile', alpha=0.159, random_state=0, verbose=1, **best_params)\n",
    "fit_and_test_model(hgbr_q_low, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hgbr_q_high = sklearn.ensemble.HistGradientBoostingRegressor(loss='quantile', quantile=0.841, random_state=0, verbose=1, **hgbr_params)\n",
    "\n",
    "#gbr_q_high = sklearn.ensemble.GradientBoostingRegressor(loss='quantile', alpha=0.841, random_state=0, verbose=1, **best_params)\n",
    "fit_and_test_model(hgbr_q_high, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23195c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(hgbr, f'models/{unknown_or_known}_runs_hgbr_{shared.race_id_str()}.sav')\n",
    "joblib.dump(hgbr_q_low, f'models/{unknown_or_known}_runs_hgbr_q_low_{shared.race_id_str()}.sav')\n",
    "joblib.dump(hgbr_q_high, f'models/{unknown_or_known}_runs_hgbr_q_high_{shared.race_id_str()}.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
