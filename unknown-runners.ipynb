{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file_name = 'data/runs_ju.tsv'\n",
    "runs = pd.read_csv(in_file_name, delimiter=\"\\t\")\n",
    "runs = runs.assign(leg_id=runs.leg.astype(str))\n",
    "runs = runs.assign(num_runs=runs.num_runs.astype(str))\n",
    "runs = runs.drop([\"leg\", \"team\"], axis=1)\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n",
    "// # To disable auto-scrolling, execute this javascript in a notebook cell before other cells are executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={})\n",
    "g = sns.FacetGrid(runs, col=\"leg_id\", hue=\"year\", xlim=(0,runs.team_id.max()), ylim=(4,20), height=6, aspect=1, col_wrap=2, legend_out=False)\n",
    "g.map(sns.regplot, \"team_id\", \"pace\", scatter_kws={'alpha':0.1}, order=2).add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(runs, hue=\"year\", height=8, aspect=2, xlim=(5,20), margin_titles=True, legend_out=False) # no facet here\n",
    "g.map(sns.distplot, \"pace\", hist=False).add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(runs, hue=\"leg_id\", height=8, aspect=2, xlim=(5,20), margin_titles=True, legend_out=False) # no facet here\n",
    "g.map(sns.distplot, \"pace\", hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(runs, hue=\"num_runs\", height=8, aspect=2, xlim=(5,20), ylim=(0,0.4), margin_titles=True, legend_out=False) # no facet here\n",
    "g.map(sns.distplot, \"pace\", hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(runs, hue=\"team_country\", height=8, aspect=2, xlim=(5,20), ylim=(0,0.5), margin_titles=True, legend_out=False) # no facet here\n",
    "g.map(sns.distplot, \"pace\", hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(runs, height=8, aspect=2, xlim=(5,25), margin_titles=True) # no facet here\n",
    "g.map(sns.distplot, \"pace\", hist=True, fit=lognorm).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(runs, hue=\"year\", row=\"leg_id\",  aspect=3, xlim=(5,20), margin_titles=True, legend_out=False)\n",
    "g.map(sns.distplot, \"pace\", hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(runs, row=\"year\", col=\"leg_id\", height=6, xlim=(5,20), margin_titles=True, despine=True)\n",
    "g.map(sns.distplot, \"pace\", hist_kws={'alpha':0.8}, fit=lognorm).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.sort_values(by=\"pace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.sort_values(by=\"num_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[\"first_name\"] = runs.name.str.split(\" \", expand=True).iloc[:,0]\n",
    "\n",
    "counts = runs[\"first_name\"].value_counts()\n",
    "top_counts = counts[counts > 200]\n",
    "\n",
    "runs[\"top_first_name\"] = runs[\"first_name\"]\n",
    "\n",
    "def top_name(first_name): \n",
    "    if first_name in top_counts:\n",
    "        return first_name\n",
    "    else:\n",
    "        return  \"NA\"\n",
    "    \n",
    "runs[\"top_first_name\"] = runs.apply(lambda run: top_name(run[\"first_name\"]), axis=1)\n",
    "#g.map(sns.regplot, \"team_id\", \"pace\", scatter_kws={'alpha':0.1}, order=2).add_legend()\n",
    "top_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = sns.FacetGrid(runs, hue=\"top_first_name\", height=8, aspect=2, xlim=(5,20), margin_titles=True) # no facet here\n",
    "#g.map(sns.distplot, \"pace\", hist=False).add_legend()\n",
    "plt.figure(figsize=(16, 30))\n",
    "ax_names = sns.boxplot(y=\"top_first_name\", x=\"pace\", data=runs, fliersize=0.5, order=top_counts.index.tolist())\n",
    "ax_names.set_xlim(4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_country_counts = runs[\"team_country\"].value_counts()\n",
    "team_country_top_counts = team_country_counts[team_country_counts > 200]\n",
    "\n",
    "runs[\"top_team_country\"] = runs[\"team_country\"]\n",
    "\n",
    "def top_country(team_country): \n",
    "    if team_country in team_country_top_counts:\n",
    "        return team_country\n",
    "    else:\n",
    "        return  \"OTHER\"\n",
    "    \n",
    "runs[\"top_team_country\"] = runs.apply(lambda run: top_country(run[\"team_country\"]), axis=1)\n",
    "#g.map(sns.regplot, \"team_id\", \"pace\", scatter_kws={'alpha':0.1}, order=2).add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "ax_names = sns.boxplot(y=\"top_team_country\", x=\"pace\", data=runs, fliersize=0.5, order=team_country_top_counts.index.tolist())\n",
    "ax_names.set_xlim(4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(runs, hue=\"top_team_country\", height=8, aspect=2, xlim=(5,20), ylim=(0,0.5), margin_titles=True, legend_out=False) # no facet here\n",
    "g.map(sns.distplot, \"pace\", hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs\n",
    "runs = runs.assign(team_id_log=np.log(runs.team_id))\n",
    "runs = runs.assign(team_id_log10=np.log10(runs.team_id))\n",
    "runs = runs.assign(team_id_square=np.square(runs.team_id))\n",
    "\n",
    "first_names = pd.get_dummies(runs[[\"top_first_name\", \"leg_id\", \"num_runs\", \"top_team_country\"]])\n",
    "first_names[[\"team_id_log\", \"team_id_log10\", \"team_id_square\"]] = runs[[\"team_id_log\", \"team_id_log10\", \"team_id_square\"]]\n",
    "first_names.insert(0, \"team_id\", runs[\"team_id\"])\n",
    "\n",
    "import json\n",
    "with open(f\"data/unknown_runners_feature_columns.json\", 'w') as outfile:\n",
    "    json.dump(first_names.columns.tolist(), outfile)\n",
    "\n",
    "x = first_names.values\n",
    "y = runs.pace.values\n",
    "\n",
    "y = y.reshape(len(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(x_train.shape)\n",
    "display(y_train.shape)\n",
    "display(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_names.columns.shape\n",
    "#regr.coef_[0].shape\n",
    "coefs = pd.DataFrame({'feature':first_names.columns, 'coef':regr.coef_[0]})\n",
    "coefs['feature'] = coefs['feature'].str.replace('top_first_name_','')\n",
    "display(coefs.sort_values(by=\"coef\").head(20))\n",
    "display(coefs.sort_values(by=\"coef\", ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "print(\"Mean squared error: %.3f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Explained variance score: %.3f' % r2_score(y_test, y_pred))\n",
    "y_pred\n",
    "\n",
    "# Simple linear: Mean squared error: 6.44 Explained variance score: 0.30\n",
    "# log + square = Mean squared error: 6.21 Explained variance score: 0.320\n",
    "# 100 first names + leg_id = Mean squared error: 7.842 Explained variance score: 0.101\n",
    "# 452 first names + leg_id + log + square = Mean squared error: 5.387 Explained variance score: 0.382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it as in the example at http://scikit-learn.org/\n",
    "plt.scatter(x_test[:,0], y_test,  color='red', alpha=0.01)\n",
    "plt.scatter(x_test[:,0], y_pred, color='blue', alpha=0.01)\n",
    "plt.ylim(4, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(n_estimators=500, random_state=0, verbose=1, n_jobs=-1,\n",
    "                          max_depth= 31, \n",
    "                           max_features=\"auto\", \n",
    "                           max_leaf_nodes= 187, \n",
    "                           min_impurity_decrease= 0.00026892804687183225, \n",
    "                           min_samples_leaf= 0.0027584156528699683, \n",
    "                           min_samples_split= 21, \n",
    "                           min_weight_fraction_leaf= 0.00837)\n",
    "rf.fit(x_train, y_train.ravel())\n",
    "# Make predictions using the testing set\n",
    "rf_y_pred = rf.predict(x_test)\n",
    "\n",
    "print(\"Mean squared error: %.3f\"\n",
    "      % mean_squared_error(y_test, rf_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Explained variance score: %.3f\" % r2_score(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sklearn\n",
    "gbr = sklearn.ensemble.GradientBoostingRegressor(n_estimators=110,\n",
    "                                                 criterion='friedman_mse', \n",
    "             learning_rate=0.10927990420965396, loss='ls', max_depth=1,\n",
    "             max_features='auto', max_leaf_nodes=156,\n",
    "             min_impurity_decrease=0.0, \n",
    "             min_samples_leaf=1, min_samples_split=2,\n",
    "             min_weight_fraction_leaf=0.0, \n",
    "             random_state=0,\n",
    "             subsample=0.8209381840043655, \n",
    "             verbose=1)\n",
    "#gbr = sklearn.ensemble.GradientBoostingRegressor(n_estimators=3100, random_state=0, verbose=1,  max_features=\"log2\")\n",
    "\n",
    "gbr.fit(x_train, y_train.ravel())\n",
    "y_gbr_pred = gbr.predict(x_test)\n",
    "print(\"Mean squared error: %.3f\" % mean_squared_error(y_test, y_gbr_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Explained variance score: %.3f' % r2_score(y_test, y_gbr_pred))\n",
    "\n",
    "#print(f\"feature_importances_: {gbr.feature_importances_}\")\n",
    "gbr_features = pd.DataFrame({'feature':first_names.columns, 'importance': gbr.feature_importances_})\n",
    "gbr_features['feature'] = gbr_features['feature'].str.replace('top_first_name_','')\n",
    "display(gbr_features.sort_values(by=\"importance\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.4f} (std: {1:.4f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "#specify parameters and distributions to sample from\n",
    "crf = sklearn.ensemble.GradientBoostingRegressor(n_estimators=1000, \n",
    "                                                 random_state=0, \n",
    "                                                 verbose=1, \n",
    "                                                 n_iter_no_change=100, tol=0.000001)\n",
    "\n",
    "param_dist_gbr = { \n",
    "    \"max_leaf_nodes\": np.rint(np.abs(norm.rvs(loc=156, scale=10, size=1000))).astype(\"int\"), \n",
    "    \"max_depth\": np.rint(np.abs(norm.rvs(loc=1, scale=1, size=1000))).astype(\"int\"), \n",
    "    \"max_features\": [\"auto\", \"sqrt\"], \n",
    "    \"learning_rate\": np.abs(norm.rvs(loc=0.11, scale=0.01, size=1000)), \n",
    "    \"subsample\": np.abs(norm.rvs(loc=0.83, scale=0.1, size=1000)) }\n",
    "\n",
    "n_iter_search = 5 \n",
    "random_search = RandomizedSearchCV(crf, param_distributions=param_dist_gbr, random_state=2019, \n",
    "                                   n_iter=n_iter_search, cv=3, n_jobs=-1, error_score=0, verbose=1)\n",
    "\n",
    "start = time() \n",
    "random_search.fit(x_train, y_train.ravel()) \n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\" \" parameter settings.\" % ((time() - start), n_iter_search)) \n",
    "report(random_search.cv_results_) \n",
    "print(random_search.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_y_pred = random_search.predict(x_test)\n",
    "\n",
    "print(\"Mean squared error: %.3f\"\n",
    "      % mean_squared_error(y_test, crf_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Explained variance score: %.3f' % r2_score(y_test, crf_y_pred))\n",
    "r2 = r2_score(y_test, crf_y_pred)\n",
    "\n",
    "with open(f\"data/rf-best_estimator_{r2:.3f}.json\", 'w') as outfile:\n",
    "    outfile.write(str(random_search.best_estimator_.get_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it as in the example at http://scikit-learn.org/\n",
    "#plt.scatter(x_test[:,0], y_test,  color='red', alpha=0.01)\n",
    "#plt.scatter(x_test[:,0], rf_y_pred, color='blue', alpha=0.01)\n",
    "#plt.ylim(4, 20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1)\n",
    "#y_rbf_pred = svr_rbf.fit(x_train, y_train.ravel()).predict(x_test)\n",
    "#print(\"Mean squared error: %.3f\"\n",
    "#      % mean_squared_error(y_test, y_rbf_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "#print('Explained variance score: %.3f' % r2_score(y_test, y_rbf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = linear_model.BayesianRidge()\n",
    "br.fit(x_train, y_train.ravel())\n",
    "y_br_pred = br.predict(x_test)\n",
    "print(\"Mean squared error: %.3f\"\n",
    "      % mean_squared_error(y_test, y_br_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Explained variance score: %.3f' % r2_score(y_test, y_br_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustly fit linear model with RANSAC algorithm\n",
    "ransac = linear_model.RANSACRegressor()\n",
    "ransac.fit(x_train, y_train.ravel())\n",
    "y_ransac_pred = ransac.predict(x_test)\n",
    "print(\"Mean squared error: %.3f\"\n",
    "      % mean_squared_error(y_test, y_ransac_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Explained variance score: %.3f' % r2_score(y_test, y_ransac_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log2(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}