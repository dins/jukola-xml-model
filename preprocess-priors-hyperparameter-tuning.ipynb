{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shared\n",
    "import static_individual_estimates\n",
    "import json\n",
    "import logging \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ve_or_ju = shared.race_type()\n",
    "ve_or_ju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y, features) = static_individual_estimates.preprocess_countries_names_and_features()\n",
    "features.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(x.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = [f'x.shape: {x.shape}', f'y.shape: {y.shape}', features.info()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2019)\n",
    "reports.append(f'x_train: {x_train.shape}, x_test: {x_test.shape}')\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index_of_team_id = list(features.columns).index(\"team_id\")\n",
    "def fit_and_test_model(model, x_train, x_test, y_train, y_test, fit_params={}):\n",
    "    model.fit(x_train, y_train.ravel(), **fit_params)\n",
    "    y_pred = np.exp(model.predict(x_test))\n",
    "    print(f\"Shapes: y_test={np.exp(y_test).shape} y_pred={y_pred.shape}\")\n",
    "    print(\"Mean absolute percetange error: %.3f\" %  mean_absolute_percentage_error(np.exp(y_test), y_pred))\n",
    "    print(\"Median absolute error: %.3f\" %  median_absolute_error(np.exp(y_test), y_pred))\n",
    "    print(\"Mean squared error: %.3f\" % mean_squared_error(np.exp(y_test), y_pred))\n",
    "    print('Explained variance score: %.3f' % r2_score(np.exp(y_test), y_pred))\n",
    "\n",
    "    reports.append(f'{type(model)}: {model.get_params()}')\n",
    "    reports.append(f'Explained variance score: {r2_score(np.exp(y_test), y_pred).round(3)}')\n",
    "    \n",
    "    plt.scatter(x_test[:,index_of_team_id], np.exp(y_test),  color='red', alpha=0.01)\n",
    "    plt.scatter(x_test[:,index_of_team_id], y_pred, color='blue', alpha=0.01)\n",
    "    plt.ylim(4, 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "fit_and_test_model(linear, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame({'name':features.keys(), 'coef':linear.coef_})\n",
    "display(coefs.sort_values(by=\"coef\", ascending=False).head(20).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "if ve_or_ju == \"ve\":\n",
    "    gbr_num_estimators=200\n",
    "else:\n",
    "    gbr_num_estimators=800\n",
    "\n",
    "\n",
    "X = x_train\n",
    "y = y_train\n",
    "# The list of hyper-parameters we want to optimize. For each one we define the\n",
    "# bounds, the corresponding scikit-learn parameter name, as well as how to\n",
    "# sample values from that dimension (`'log-uniform'` for the learning rate)\n",
    "space  = [\n",
    "          Integer(2, 10, name='max_depth'),\n",
    "          Integer(gbr_num_estimators * 0.3, gbr_num_estimators * 1.25, name='n_estimators'),\n",
    "          #Integer(225, 235, name='n_estimators'),\n",
    "          Categorical([0.05, 0.07, 0.08], name='learning_rate')\n",
    "]\n",
    "\n",
    "reg = sklearn.ensemble.GradientBoostingRegressor(random_state=0)\n",
    "# this decorator allows your objective function to receive a the parameters as\n",
    "# keyword arguments. This is particularly convenient when you want to set\n",
    "# scikit-learn estimator parameters\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=5, n_jobs=-1, verbose=1,\n",
    "                                    scoring=\"neg_mean_absolute_percentage_error\"))\n",
    "\n",
    "#n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=30, random_state=0)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plot_convergence(res_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {value_and_specs[1].name: value_and_specs[0]  for value_and_specs in zip(res_gp.x, space)}\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"best_params: {best_params}\")\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Custom encoder for numpy data types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                            np.int16, np.int32, np.int64, np.uint8,\n",
    "                            np.uint16, np.uint32, np.uint64)):\n",
    "\n",
    "            return int(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.complex_, np.complex64, np.complex128)):\n",
    "            return {'real': obj.real, 'imag': obj.imag}\n",
    "\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "\n",
    "        elif isinstance(obj, (np.bool_)):\n",
    "            return bool(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.void)): \n",
    "            return None\n",
    "\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "    \n",
    "with open(f\"models/best_params_gbr_{shared.race_id_str()}.json\", 'w') as outfile:\n",
    "    json.dump(best_params, outfile, cls=NumpyEncoder)\n",
    "    \n",
    "with open(f\"models/best_params_gbr_{shared.race_id_str()}.json\") as infile:\n",
    "    best_params = json.load(infile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = sklearn.ensemble.GradientBoostingRegressor(random_state=0, verbose=1, **best_params)\n",
    "\n",
    "fit_and_test_model(gbr, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful, impurity-based feature importances can be misleading for high cardinality features (many unique values). \n",
    "gbr_features = pd.DataFrame({'feature':features.columns, 'importance': gbr.feature_importances_})\n",
    "display(gbr_features.sort_values(by=\"importance\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_num_estimators_quantile=int(gbr_num_estimators/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_q_low = sklearn.ensemble.GradientBoostingRegressor(loss='quantile', alpha=0.159, random_state=0, verbose=1, **best_params)\n",
    "fit_and_test_model(gbr_q_low, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_q_high = sklearn.ensemble.GradientBoostingRegressor(loss='quantile', alpha=0.841, random_state=0, verbose=1, **best_params)\n",
    "fit_and_test_model(gbr_q_high, x_train, x_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = time.time()\n",
    "shared.log_df(f\"{shared.race_id_str()} runtime {round(((endTime - startTime)/ 60), 2)} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
