{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shared\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import prepare_run_features\n",
    "#os.environ['FORECAST_YEAR'] = \"2019\"\n",
    "unknown_or_known = os.environ.get('UNKNOWN_OR_KNOWN', \"unknown\")\n",
    "runners_with_history =  unknown_or_known == \"known\"\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, features = prepare_run_features.prepare_run_features(runners_with_history)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08449b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if runners_with_history:\n",
    "    runners_row_indexer = features[\"runs\"] > 1\n",
    "else:\n",
    "    runners_row_indexer = features[\"runs\"] == 1\n",
    "    \n",
    "features = features[runners_row_indexer]\n",
    "x = x[runners_row_indexer]\n",
    "y = y[runners_row_indexer]\n",
    "display(y.shape)\n",
    "display(x.shape)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05, random_state=2019)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.01, random_state=2023)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14264afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index_of_team_id = list(features.columns).index(\"team_id\")\n",
    "def fit_and_test_model(model, x_train, x_test, y_train, y_test, fit_params={}):\n",
    "    model.fit(x_train, y_train.ravel(), **fit_params)\n",
    "    y_pred = np.exp(model.predict(x_test))\n",
    "    print(f\"Shapes: y_test={np.exp(y_test).shape} y_pred={y_pred.shape}\")\n",
    "    print(\"Mean absolute percetange error: %.3f\" %  mean_absolute_percentage_error(np.exp(y_test), y_pred))\n",
    "    print(\"Median absolute error: %.3f\" %  median_absolute_error(np.exp(y_test), y_pred))\n",
    "    print(\"Mean squared error: %.3f\" % mean_squared_error(np.exp(y_test), y_pred))\n",
    "    print('Explained variance score: %.3f' % r2_score(np.exp(y_test), y_pred))\n",
    "    \n",
    "    plt.scatter(x_test[:,index_of_team_id], np.exp(y_test),  color='red', alpha=0.01)\n",
    "    plt.scatter(x_test[:,index_of_team_id], y_pred, color='blue', alpha=0.01)\n",
    "    plt.ylim(4, 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba35478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "if shared.race_type() == \"ve\":\n",
    "    max_iter=200\n",
    "else:\n",
    "    max_iter=300\n",
    "\n",
    "if runners_with_history:\n",
    "    max_iter = 2 * max_iter\n",
    "\n",
    "X = x_train\n",
    "y = y_train\n",
    "# The list of hyper-parameters we want to optimize. For each one we define the\n",
    "# bounds, the corresponding scikit-learn parameter name, as well as how to\n",
    "# sample values from that dimension (`'log-uniform'` for the learning rate)\n",
    "space  = [\n",
    "          Integer(5, 60, name='max_depth'),\n",
    "          Integer(max_iter * 0.5, max_iter * 2, name='max_iter'),\n",
    "          Real(low=0.005, high=0.2, name='learning_rate')\n",
    "]\n",
    "\n",
    "reg = sklearn.ensemble.HistGradientBoostingRegressor(random_state=0)\n",
    "# this decorator allows your objective function to receive a the parameters as\n",
    "# keyword arguments. This is particularly convenient when you want to set\n",
    "# scikit-learn estimator parameters\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=5, n_jobs=-1, verbose=1,\n",
    "                                    scoring=\"neg_mean_absolute_percentage_error\"))\n",
    "\n",
    "#n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from skopt import gp_minimize\n",
    "np.int = int\n",
    "res_gp = gp_minimize(objective, space, n_calls=40, random_state=0)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40092b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {value_and_specs[1].name: value_and_specs[0]  for value_and_specs in zip(res_gp.x, space)}\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plot_convergence(res_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c235d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"best_params: {best_params}\")\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Custom encoder for numpy data types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                            np.int16, np.int32, np.int64, np.uint8,\n",
    "                            np.uint16, np.uint32, np.uint64)):\n",
    "\n",
    "            return int(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.complex_, np.complex64, np.complex128)):\n",
    "            return {'real': obj.real, 'imag': obj.imag}\n",
    "\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "\n",
    "        elif isinstance(obj, (np.bool_)):\n",
    "            return bool(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.void)): \n",
    "            return None\n",
    "\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "#json_path = f\"models/best_params_unk_runs_hgbr_{shared.race_id_str()}.json\"    \n",
    "json_path = f\"models/best_params_{unknown_or_known}_runs_hgbr_{shared.race_id_str()}.json\"    \n",
    "with open(json_path, 'w') as outfile:\n",
    "    json.dump(best_params, outfile, cls=NumpyEncoder)\n",
    "    \n",
    "with open(json_path) as infile:\n",
    "    best_params = json.load(infile)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
